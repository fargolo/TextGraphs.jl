var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = TextGraphs","category":"page"},{"location":"#TextGraphs","page":"Home","title":"TextGraphs","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for TextGraphs.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [TextGraphs]","category":"page"},{"location":"#TextGraphs.add_prop_label_tokens-Tuple{MetaGraphs.AbstractMetaGraph, Any}","page":"Home","title":"TextGraphs.add_prop_label_tokens","text":"add_prop_label_tokens(metagraph,metagraph_unique_tokens)\n\nAdd tokens as properties of nodes in a MetaGraph.\n\nThis function is used internally to attach word labels to each node. Unique tokens must have length equal to the number of vertices\n\n\n\n\n\n","category":"method"},{"location":"#TextGraphs.link_consecutive-Tuple{AbstractArray}","page":"Home","title":"TextGraphs.link_consecutive","text":"link_consecutive(array_with_tokens)\n\nTransform serialized tokens into a directed graph. \n\nThis function is used internally to build graphs from text. Each token has an unique node in the graph.\n\n\n\n\n\n","category":"method"},{"location":"#TextGraphs.naive_graph-Tuple{AbstractString}","page":"Home","title":"TextGraphs.naive_graph","text":"naive_graph(raw_text::AbstractString)\n\nBuild graph from text (AbstractString) with unprocessed words.\n\n\n\n\n\n","category":"method"},{"location":"#TextGraphs.phrases_graph-Tuple{AbstractString}","page":"Home","title":"TextGraphs.phrases_graph","text":"phrases_graph(my_text)\n\nBuild graph from text (AbstractString) using sentences as unique tokens. \n\n\n\n\n\n","category":"method"},{"location":"#TextGraphs.stem_graph-Tuple{AbstractString}","page":"Home","title":"TextGraphs.stem_graph","text":"stem_graph(my_text)\n\nBuild graph from text (AbstractString) using lemmatized words. \n\nStemming is performed with Snowball.jl stemmer. Default language is \"portugese\". \n\n\n\n\n\n","category":"method"}]
}
